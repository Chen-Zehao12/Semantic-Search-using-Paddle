{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:00.245218Z",
     "iopub.status.busy": "2022-08-04T12:58:00.244697Z",
     "iopub.status.idle": "2022-08-04T12:58:00.250469Z",
     "shell.execute_reply": "2022-08-04T12:58:00.249603Z",
     "shell.execute_reply.started": "2022-08-04T12:58:00.245192Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:00.253530Z",
     "iopub.status.busy": "2022-08-04T12:58:00.253076Z",
     "iopub.status.idle": "2022-08-04T12:58:02.785896Z",
     "shell.execute_reply": "2022-08-04T12:58:02.784774Z",
     "shell.execute_reply.started": "2022-08-04T12:58:00.253507Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlenlp==2.3.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.3.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (4.64.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (0.1.96)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (4.1.0)\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (0.70.11.1)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (0.42.1)\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (0.9.8)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (1.2.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (2.4.0)\n",
      "Requirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (1.1.0)\n",
      "Requirement already satisfied: dill<0.3.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (0.3.3)\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (3.20.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.3.4) (0.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (2.24.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (0.8.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (4.2.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (9.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (1.19.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (2022.7.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (3.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp==2.3.4) (0.18.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp==2.3.4) (0.24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp==2.3.4) (5.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp==2.3.4) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp==2.3.4) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets>=2.0.0->paddlenlp==2.3.4) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.3.4) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.3.4) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.3.4) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp==2.3.4) (2019.9.11)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.3.4) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.3.4) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.3.4) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (2.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (1.8.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp==2.3.4) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp==2.3.4) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->datasets>=2.0.0->paddlenlp==2.3.4) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->datasets>=2.0.0->paddlenlp==2.3.4) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=2.0.0->paddlenlp==2.3.4) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp==2.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:02.788138Z",
     "iopub.status.busy": "2022-08-04T12:58:02.787617Z",
     "iopub.status.idle": "2022-08-04T12:58:05.766843Z",
     "shell.execute_reply": "2022-08-04T12:58:05.765893Z",
     "shell.execute_reply.started": "2022-08-04T12:58:02.788108Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入系统库\n",
    "import abc\n",
    "import sys\n",
    "from functools import partial\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "# 导入python的其他库\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "# 导入Paddle库\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle import inference\n",
    "\n",
    "#导入PaddleNLP相关的库\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset, MapDataset\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "from paddlenlp.utils.downloader import get_path_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:05.768862Z",
     "iopub.status.busy": "2022-08-04T12:58:05.768121Z",
     "iopub.status.idle": "2022-08-04T12:58:05.773257Z",
     "shell.execute_reply": "2022-08-04T12:58:05.772618Z",
     "shell.execute_reply.started": "2022-08-04T12:58:05.768830Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "scale=20 # 推荐值: 10 ~ 30\n",
    "margin=0.1 # 推荐值: 0.0 ~ 0.2\n",
    "# SimCSE的dropout的参数，也可以使用预训练语言模型默认的dropout参数\n",
    "dropout=0.2\n",
    "# 向量映射的维度，默认的输出是768维，推荐通过线性层映射成256维\n",
    "output_emb_size=256\n",
    "# 语义索引的维度，可以根据自己的情况调节长度\n",
    "max_seq_length=150\n",
    "# 根据经验 batch_size越大效果越好\n",
    "batch_size=32\n",
    "# 训练的epoch数目\n",
    "epochs=1\n",
    "weight_decay=0.0\n",
    "# 学习率\n",
    "learning_rate=5E-5\n",
    "warmup_proportion=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:14.875152Z",
     "iopub.status.busy": "2022-08-04T12:58:14.874707Z",
     "iopub.status.idle": "2022-08-04T12:58:14.879378Z",
     "shell.execute_reply": "2022-08-04T12:58:14.878425Z",
     "shell.execute_reply.started": "2022-08-04T12:58:14.875121Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 使用roberta-wwm-ext-large模型\n",
    "MODEL_NAME_OR_PATH = \"hfl/roberta-wwm-ext-large\"\n",
    "# 从保存的参数中读取\n",
    "# MODEL_NAME_OR_PATH = 'checkpoint'\n",
    "pretrained_model = ppnlp.transformers.RobertaModel.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH, \n",
    "    hidden_dropout_prob=dropout,\n",
    "    attention_probs_dropout_prob=dropout)\n",
    "# 定义模型对应的tokenizer，tokenizer可以把原始输入文本转化成模型model可接受的输入数据格式。需注意tokenizer类要与选择的模型相对应，具体可以查看PaddleNLP相关文档\n",
    "tokenizer = ppnlp.transformers.RobertaTokenizer.from_pretrained(MODEL_NAME_OR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:14.880888Z",
     "iopub.status.busy": "2022-08-04T12:58:14.880564Z",
     "iopub.status.idle": "2022-08-04T12:58:19.680459Z",
     "shell.execute_reply": "2022-08-04T12:58:19.679392Z",
     "shell.execute_reply.started": "2022-08-04T12:58:14.880864Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据读取逻辑\n",
    "def read_simcse_text(data_path):\n",
    "    \"\"\"Reads data.\"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if(i==0):\n",
    "                continue\n",
    "            data = line.rstrip().split('\\t')\n",
    "            if len(data) != 2:\n",
    "                continue\n",
    "            data = data[0]\n",
    "            # 这里的text_a和text_b是一样的\n",
    "            yield {'text_a': data, 'text_b': data}\n",
    "\n",
    "train_set_file='data/Chinese/data.csv'\n",
    "train_ds = load_dataset(read_simcse_text, data_path=train_set_file, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:19.682363Z",
     "iopub.status.busy": "2022-08-04T12:58:19.681916Z",
     "iopub.status.idle": "2022-08-04T12:58:19.694994Z",
     "shell.execute_reply": "2022-08-04T12:58:19.694199Z",
     "shell.execute_reply.started": "2022-08-04T12:58:19.682331Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 明文数据 -> ID 序列训练数据\n",
    "\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    if mode == 'train':\n",
    "        # 分布式批采样器加载数据的一个子集。\n",
    "        # 每个进程可以传递给DataLoader一个DistributedBatchSampler的实例，每个进程加载原始数据的一个子集。\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        # 批采样器的基础实现，\n",
    "        # 用于 paddle.io.DataLoader 中迭代式获取mini-batch的样本下标数组，数组长度与 batch_size 一致。\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    # 组装mini-batch\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "def convert_example(example, tokenizer, max_seq_length=512, do_evalute=False):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for key, text in example.items():\n",
    "        if 'label' in key:\n",
    "            # do_evaluate\n",
    "            result += [example['label']]\n",
    "        else:\n",
    "            # do_train\n",
    "            encoded_inputs = tokenizer(text=text, max_seq_len=max_seq_length)\n",
    "            input_ids = encoded_inputs[\"input_ids\"]\n",
    "            token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "            result += [input_ids, token_type_ids]\n",
    "\n",
    "    return result\n",
    "\n",
    "# 给convert_example赋予默认的值，如tokenizer，max_seq_length\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "# [pad]对齐的函数\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # query_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # query_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # title_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # tilte_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# 构建训练的Dataloader\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:19.696609Z",
     "iopub.status.busy": "2022-08-04T12:58:19.696226Z",
     "iopub.status.idle": "2022-08-04T12:58:19.710306Z",
     "shell.execute_reply": "2022-08-04T12:58:19.709535Z",
     "shell.execute_reply.started": "2022-08-04T12:58:19.696581Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SimCSE(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 pretrained_model,\n",
    "                 dropout=None,\n",
    "                 margin=0.0,\n",
    "                 scale=20,\n",
    "                 output_emb_size=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.ptm = pretrained_model\n",
    "        # 显式的加一个dropout来控制\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "\n",
    "        # if output_emb_size is greater than 0, then add Linear layer to reduce embedding_size, \n",
    "        # 考虑到性能和效率，我们推荐把output_emb_size设置成256\n",
    "        # 向量越大，语义信息越丰富，但消耗资源越多\n",
    "        self.output_emb_size = output_emb_size\n",
    "        if output_emb_size > 0:\n",
    "            weight_attr = paddle.ParamAttr(\n",
    "                initializer=nn.initializer.TruncatedNormal(std=0.02))\n",
    "            self.emb_reduce_linear = paddle.nn.Linear(\n",
    "                1024, output_emb_size, weight_attr=weight_attr)\n",
    "\n",
    "        self.margin = margin\n",
    "        # 为了使余弦相似度更容易收敛，我们选择把计算出来的余弦相似度扩大scale倍，一般设置成20左右\n",
    "        self.sacle = scale\n",
    "\n",
    "    # 加入jit注释能够把该提取向量的函数导出成静态图\n",
    "    # 对应input_id,token_type_id两个\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None,\n",
    "                             with_pooler=True):\n",
    "\n",
    "        # Note: cls_embedding is poolerd embedding with act tanh \n",
    "        sequence_output, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                                  position_ids, attention_mask)\n",
    "\n",
    "        if with_pooler == False:\n",
    "            cls_embedding = sequence_output[:, 0, :]\n",
    "\n",
    "        if self.output_emb_size > 0:\n",
    "            cls_embedding = self.emb_reduce_linear(cls_embedding)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/functional/normalize_cn.html\n",
    "        cls_embedding = F.normalize(cls_embedding, p=2, axis=-1)\n",
    "        return cls_embedding\n",
    "\n",
    "    def forward(self,\n",
    "                query_input_ids,\n",
    "                title_input_ids,\n",
    "                query_token_type_ids=None,\n",
    "                query_position_ids=None,\n",
    "                query_attention_mask=None,\n",
    "                title_token_type_ids=None,\n",
    "                title_position_ids=None,\n",
    "                title_attention_mask=None):\n",
    "        \n",
    "        # 第 1 次编码: 文本经过无监督语义索引模型编码后的语义向量 \n",
    "        # [N, 768]\n",
    "        query_cls_embedding = self.get_pooled_embedding(\n",
    "            query_input_ids, query_token_type_ids, query_position_ids,\n",
    "            query_attention_mask)\n",
    "\n",
    "        # 第 2 次编码: 文本经过无监督语义索引模型编码后的语义向量 \n",
    "        # [N, 768]\n",
    "        title_cls_embedding = self.get_pooled_embedding(\n",
    "            title_input_ids, title_token_type_ids, title_position_ids,\n",
    "            title_attention_mask)\n",
    "\n",
    "        # 相似度矩阵: [N, N]\n",
    "        cosine_sim = paddle.matmul(\n",
    "            query_cls_embedding, title_cls_embedding, transpose_y=True)\n",
    "\n",
    "        # substract margin from all positive samples cosine_sim()\n",
    "        # 填充self.margin值，比如margin为0.2，query_cls_embedding.shape[0]=2 \n",
    "        # margin_diag: [0.2,0.2]\n",
    "        margin_diag = paddle.full(\n",
    "            shape=[query_cls_embedding.shape[0]],\n",
    "            fill_value=self.margin,\n",
    "            dtype=paddle.get_default_dtype())\n",
    "        # input paddle.diag(margin_diag): [[0.2,0],[0,0.2]]\n",
    "        # input cosine_sim : [[1.0,0.6],[0.6,1.0]]\n",
    "        # output cosine_sim: [[0.8,0.6],[0.6,0.8]]\n",
    "        cosine_sim = cosine_sim - paddle.diag(margin_diag)\n",
    "\n",
    "        # scale cosine to ease training converge\n",
    "        cosine_sim *= self.sacle\n",
    "\n",
    "        # 转化成多分类任务: 对角线元素是正例，其余元素为负例\n",
    "        # labels : [0,1,2,3]\n",
    "        labels = paddle.arange(0, query_cls_embedding.shape[0], dtype='int64')\n",
    "        # labels : [[0],[1],[2],[3]]\n",
    "        labels = paddle.reshape(labels, shape=[-1, 1])\n",
    "\n",
    "        # 交叉熵损失函数\n",
    "        loss = F.cross_entropy(input=cosine_sim, label=labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:19.711722Z",
     "iopub.status.busy": "2022-08-04T12:58:19.711351Z",
     "iopub.status.idle": "2022-08-04T12:58:19.721907Z",
     "shell.execute_reply": "2022-08-04T12:58:19.721133Z",
     "shell.execute_reply.started": "2022-08-04T12:58:19.711696Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 实例化SimCSE\n",
    "model = SimCSE(\n",
    "        pretrained_model,\n",
    "        margin=margin,\n",
    "        scale=scale,\n",
    "        output_emb_size=output_emb_size)\n",
    "# 训练的总步数\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "# warmpup操作，学习率先上升后下降\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "# 设置优化器\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T12:58:19.725009Z",
     "iopub.status.busy": "2022-08-04T12:58:19.724657Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'paddlenlp.transformers.tokenizer_utils_base.BatchEncoding'>\n",
      "{'input_ids': [0, 19071, 143408, 69052, 31965, 274, 15256, 6768, 134648, 5392, 38409, 121088, 36480, 4, 5384, 36480, 4742, 204286, 37, 49131, 213, 36480, 4742, 204286, 108924, 38409, 10930, 37, 26240, 2825, 110239, 37, 8312, 9730, 14196, 7006, 37, 49131, 213, 36480, 4742, 1998, 43, 37462, 1278, 41284, 7006, 4, 1493, 25722, 8312, 9730, 14196, 7006, 5384, 21275, 18542, 8312, 9730, 37, 90652, 14196, 7006, 37, 10898, 15635, 5032, 4, 21275, 18542, 8312, 9730, 1189, 17973, 8312, 8312, 3136, 37, 10898, 15635, 5032, 37, 38409, 10930, 82960, 4, 10898, 15635, 5032, 1189, 90652, 14196, 7006, 82960, 4, 90652, 14196, 7006, 1189, 38409, 10930, 82960, 4, 10898, 15635, 5032, 30812, 17973, 8312, 8312, 3136, 4185, 15900, 1102, 90652, 14196, 7006, 8312, 3272, 11933, 4, 28343, 2110, 38409, 10930, 17973, 8312, 37, 2110, 90652, 14196, 7006, 164331, 30, 1516, 143408, 69052, 43, 6768, 134648, 5392, 38409, 121088, 36480, 4511, 56721, 8312, 9730, 14196, 2], 'position_ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "dict_keys(['input_ids', 'position_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 218, in _thread_loop\n",
      "    self._thread_done_event)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py\", line 121, in fetch\n",
      "    data.append(self.dataset[idx])\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dataset.py\", line 277, in __getitem__\n",
      "    ) if self._transform_pipline else self.new_data[idx]\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/datasets/dataset.py\", line 267, in _transform\n",
      "    data = fn(data)\n",
      "  File \"/tmp/ipykernel_1298/1183150353.py\", line 44, in convert_example\n",
      "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils_base.py\", line 246, in __getitem__\n",
      "    return self.data[item]\n",
      "KeyError: 'token_type_ids'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"checkpoint\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        query_input_ids, query_token_type_ids, title_input_ids, title_token_type_ids = batch\n",
    "        # 其中query和title为同一条数据\n",
    "        loss = model(\n",
    "                query_input_ids=query_input_ids,\n",
    "                title_input_ids=title_input_ids,\n",
    "                query_token_type_ids=query_token_type_ids,\n",
    "                title_token_type_ids=title_token_type_ids)\n",
    "        # 每隔10个step进行打印日志\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f\" % (global_step, epoch, step, loss))\n",
    "        # 反向\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "    \n",
    "    # 每一轮都保存模型\n",
    "    save_param_path = os.path.join(save_dir, 'model_state.pdparams')  # 保存模型参数\n",
    "    save_lr_path = os.path.join(save_dir, 'lr')\n",
    "    save_opt_path = os.path.join(save_dir, 'opt')\n",
    "\n",
    "    paddle.save(model.state_dict(), save_param_path)\n",
    "    paddle.save(lr_scheduler.state_dict(), save_lr_path)\n",
    "    paddle.save(optimizer.state_dict(), save_opt_path)\n",
    "    tokenizer.save_pretrained(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
